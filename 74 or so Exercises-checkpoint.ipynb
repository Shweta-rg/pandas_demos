{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10746d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4bd4f0",
   "metadata": {},
   "source": [
    "1) Demonstrate how to import Pandas and check the version of the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3bc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14b81925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39e16262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\n",
      "python           : 3.11.0.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.22621\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : English_United States.1252\n",
      "\n",
      "pandas           : 1.5.2\n",
      "numpy            : 1.24.1\n",
      "pytz             : 2022.6\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 65.5.0\n",
      "pip              : 22.3\n",
      "Cython           : None\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 3.1.2\n",
      "IPython          : 8.7.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.11.1\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : None\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.6.3\n",
      "numba            : None\n",
      "numexpr          : None\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.10.0\n",
      "snappy           : None\n",
      "sqlalchemy       : None\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : None\n",
      "tzdata           : None\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc4f4a",
   "metadata": {},
   "source": [
    "2) Transform this list, numpy array, and dictionary into a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b30b4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m mylist \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mabcedfghijklmnopqrstuvwxyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m list_series \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(mylist, name\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmylist\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mtype\u001b[39m(list_series)\n\u001b[0;32m      5\u001b[0m myarr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m26\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "list_series = pd.Series(mylist, name= 'mylist')\n",
    "type(list_series)\n",
    "myarr = np.arange(26)\n",
    "arr_series = pd.Series(myarr, name='myarr')\n",
    "type(arr_series)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "dict_series = pd.Series(mydict)\n",
    "type(dict_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17155a8",
   "metadata": {},
   "source": [
    "3) Convert the index of your previous series into a column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db0f1395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "a   0\n",
       "b   1\n",
       "c   2\n",
       "e   3\n",
       "d   4\n",
       "f   5\n",
       "g   6\n",
       "h   7\n",
       "i   8\n",
       "j   9\n",
       "k  10\n",
       "l  11\n",
       "m  12\n",
       "n  13\n",
       "o  14\n",
       "p  15\n",
       "q  16\n",
       "r  17\n",
       "s  18\n",
       "t  19\n",
       "u  20\n",
       "v  21\n",
       "w  22\n",
       "x  23\n",
       "y  24\n",
       "z  25"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_series.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f625f24",
   "metadata": {},
   "source": [
    "4) Combine the series below into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d268747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>j</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>o</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>p</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>x</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>y</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>z</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   a   0\n",
       "1   b   1\n",
       "2   c   2\n",
       "3   e   3\n",
       "4   d   4\n",
       "5   f   5\n",
       "6   g   6\n",
       "7   h   7\n",
       "8   i   8\n",
       "9   j   9\n",
       "10  k  10\n",
       "11  l  11\n",
       "12  m  12\n",
       "13  n  13\n",
       "14  o  14\n",
       "15  p  15\n",
       "16  q  16\n",
       "17  r  17\n",
       "18  s  18\n",
       "19  t  19\n",
       "20  u  20\n",
       "21  v  21\n",
       "22  w  22\n",
       "23  x  23\n",
       "24  y  24\n",
       "25  z  25"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "comb = pd.concat([ser1, ser2], axis =1)\n",
    "comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd8618",
   "metadata": {},
   "source": [
    "5) Give the series below a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b18f9c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'), name= 'ser')\n",
    "type(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8d244",
   "metadata": {},
   "source": [
    "6) Find the elements in the first series (ser1) not in the second series (ser2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1276978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "ans = ser1[~ser1.isin(ser2)]\n",
    "type(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336f7dd",
   "metadata": {},
   "source": [
    "7) Find the elements in both series that are not in common (remove them if they exist in both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28768232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "combine = pd.concat([ser1, ser2])\n",
    "combine\n",
    "common_list = []\n",
    "common = ser1[ser1.isin(ser2)]\n",
    "common\n",
    "#ans = ser1[~ser1.isin(ser2)]\n",
    "ans = combine[~combine.isin(common)]\n",
    "ans\n",
    "# ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "# ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "# ser_u[~ser_u.isin(ser_i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c95fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d0424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7188b5",
   "metadata": {},
   "source": [
    "8) Find the minimum, max, 25th percentile, and 75th percentile in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5a1a3ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.24135362,  9.93992351, 11.84855812, 14.49679442, 22.01086473])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "df = ser.to_frame()\n",
    "#df\n",
    "df.describe(include = 'all')\n",
    "\n",
    "\n",
    "r = np.percentile(ser, q=[0, 25, 50, 75, 100]) # we can use in further as we got array as o/p\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c1803",
   "metadata": {},
   "source": [
    "9) Obtain the count of each unique item in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "16a2880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    7\n",
       "d    7\n",
       "b    4\n",
       "c    3\n",
       "h    3\n",
       "a    2\n",
       "e    2\n",
       "g    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "ser.value_counts()\n",
    "# df = ser.to_frame()# dont change to dataframe..... value_counts dont work on dataframes\n",
    "# df\n",
    "# df[[0]].value_counts()\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449036ea",
   "metadata": {},
   "source": [
    "10) Keep the two most frequent items in the series and change all items that are not those two into \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e86f2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    4\n",
      "4    3\n",
      "1    3\n",
      "2    2\n",
      "dtype: int64\n",
      "[3, 4]\n",
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Learner_XZHCG217\\AppData\\Local\\Temp\\ipykernel_4976\\2936311664.py:7: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  list1=ser.value_counts()[:2].index.tolist()\n",
      "C:\\Users\\Learner_XZHCG217\\AppData\\Local\\Temp\\ipykernel_4976\\2936311664.py:9: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  list2=ser.value_counts()[2:].index.tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "ser2=ser.value_counts()\n",
    "print(ser2)\n",
    "#df=ser.to_frame()\n",
    "#print(df.value_counts())\n",
    "list1=ser.value_counts()[:2].index.tolist()\n",
    "print(list1)\n",
    "list2=ser.value_counts()[2:].index.tolist()\n",
    "print(list2)\n",
    "#list1=df[0].value_counts()[:2].index.tolist()\n",
    "type(list1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "543fa334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     4\n",
      "3     4\n",
      "4     4\n",
      "5     4\n",
      "6     1\n",
      "7     2\n",
      "8     3\n",
      "9     2\n",
      "10    1\n",
      "11    3\n",
      "dtype: int32\n",
      "1    4\n",
      "4    4\n",
      "2    2\n",
      "3    2\n",
      "dtype: int64\n",
      "[1, 4]\n",
      "0          1\n",
      "1          1\n",
      "2          4\n",
      "3          4\n",
      "4          4\n",
      "5          4\n",
      "6          1\n",
      "7     others\n",
      "8     others\n",
      "9     others\n",
      "10         1\n",
      "11    others\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#sushma\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print(ser)\n",
    "print(ser.value_counts())\n",
    "print(ser.value_counts().index[:2].to_list())\n",
    "ser[~ser.isin(ser.value_counts().index[:2].to_list())]=\"others\"\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ebc04b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         2\n",
       "2         3\n",
       "3         2\n",
       "4     Other\n",
       "5         3\n",
       "6         3\n",
       "7     Other\n",
       "8         2\n",
       "9     Other\n",
       "10        3\n",
       "11    Other\n",
       "dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5928875",
   "metadata": {},
   "source": [
    "11) Bin the series below into 10 equal deciles and replace the values with the bin name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "979b3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.942589\n",
      "1     0.854344\n",
      "2     0.781364\n",
      "3     0.342826\n",
      "4     0.319735\n",
      "5     0.122016\n",
      "6     0.851026\n",
      "7     0.065547\n",
      "8     0.826492\n",
      "9     0.896329\n",
      "10    0.070351\n",
      "11    0.010918\n",
      "12    0.623250\n",
      "13    0.553813\n",
      "14    0.648793\n",
      "15    0.801182\n",
      "16    0.365701\n",
      "17    0.936162\n",
      "18    0.343375\n",
      "19    0.906532\n",
      "dtype: float64\n",
      "0     d10\n",
      "1      d8\n",
      "2      d6\n",
      "3      d3\n",
      "4      d3\n",
      "5      d2\n",
      "6      d8\n",
      "7      d1\n",
      "8      d7\n",
      "9      d9\n",
      "10     d2\n",
      "11     d1\n",
      "12     d5\n",
      "13     d5\n",
      "14     d6\n",
      "15     d7\n",
      "16     d4\n",
      "17    d10\n",
      "18     d4\n",
      "19     d9\n",
      "dtype: category\n",
      "Categories (10, object): ['d1' < 'd2' < 'd3' < 'd4' ... 'd7' < 'd8' < 'd9' < 'd10']\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "print(ser)\n",
    "bin = pd.qcut(ser, q=10, labels=['d1','d2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10'])\n",
    "#bin = pd.cut(ser, 10, labels=['d1','d2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10'])\n",
    "print(bin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee79a87",
   "metadata": {},
   "source": [
    "12) Reshape the series ser into a dataframe with 7 rows and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a3513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  1  9  2  5  4\n",
      "1  5  5  8  4  1\n",
      "2  3  3  1  2  1\n",
      "3  2  7  2  1  3\n",
      "4  4  2  1  9  4\n",
      "5  4  7  9  9  3\n",
      "6  6  9  8  9  8\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c62e92",
   "metadata": {},
   "source": [
    "13) Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae884a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    1\n",
      "2    2\n",
      "3    7\n",
      "4    3\n",
      "5    8\n",
      "6    8\n",
      "dtype: int32\n",
      "Int64Index([4], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "print(ser)\n",
    "print(ser[ser.mod(3)==0].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f247",
   "metadata": {},
   "source": [
    "14) From ser, extract the items at positions in list pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42338aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "ser[pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1836c",
   "metadata": {},
   "source": [
    "15) Stack ser1 and ser2 vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfea534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "print(pd.concat([ser1,ser2], axis=1))\n",
    "print(type(pd.concat([ser1,ser2], axis=1)))\n",
    "print(pd.concat([ser1,ser2], axis=0))\n",
    "print(type(pd.concat([ser1,ser2], axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252d7bb",
   "metadata": {},
   "source": [
    "16) Get the positions of items of ser2 in ser1 as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da51891e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 5, 8]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "ser1[ser1.isin(ser2)].index.to_list()\n",
    "#ser1(ser2.isin(ser1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e34c8",
   "metadata": {},
   "source": [
    "17) Compute the mean squared error of truth and pred series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7ff599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3848393167872007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.metrics import mean_squared_error\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "mean_squared_error(truth, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf6f79",
   "metadata": {},
   "source": [
    "18) Change the first character of each word to upper case in each word of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c210bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "#newSeries = series.map(lambda x: x[0].upper() + x[1:-1] + x[-1].upper())\n",
    "#ser.map(lambda x: x[0].upper())\n",
    "ser.map(lambda x: x[0].upper()+x[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f198a",
   "metadata": {},
   "source": [
    "19) Caluculate the number of characters for each element in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216f9a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "#ser.__len__\n",
    "ser.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bcf59",
   "metadata": {},
   "source": [
    "20) Caluculate the difference of differences between the consequtive numbers of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6dba0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "5    1.0\n",
      "6    0.0\n",
      "7    2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "print(ser.diff().to_list())\n",
    "print(ser.diff().diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a2901",
   "metadata": {},
   "source": [
    "21) Convert the date-strings to a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db82de89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "pd.to_datetime(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f83c0",
   "metadata": {},
   "source": [
    "22) Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bcc124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday'], dtype='object')\n",
      "Int64Index([1, 33, 63, 94, 125, 157], dtype='int64')\n",
      "Int64Index([4, 2, 5, 3, 0, 5], dtype='int64')\n",
      "0    53\n",
      "1     5\n",
      "2     9\n",
      "3    14\n",
      "4    19\n",
      "5    23\n",
      "Name: week, dtype: UInt32\n"
     ]
    }
   ],
   "source": [
    "# ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "# pd.DatetimeIndex(ser)\n",
    "# print(pd.DatetimeIndex(ser).month_name())\n",
    "# print(pd.DatetimeIndex(ser).day_name())\n",
    "# print(pd.to_datetime(ser).dt.isocalendar().week.to_list())\n",
    "#nknk\n",
    "#test\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "print(pd.DatetimeIndex(ser).day_name())\n",
    "print(pd.DatetimeIndex(ser).day_of_year)\n",
    "print(pd.DatetimeIndex(ser).day_of_week)\n",
    "print(pd.to_datetime(ser).dt.isocalendar().week)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f97b7",
   "metadata": {},
   "source": [
    "23) Change ser to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6384074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "#ser.map(lambda x : \"04\" +x)\n",
    "pd.to_datetime(ser.map(lambda x : \"04 \" + x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb2f54",
   "metadata": {},
   "source": [
    "24) From ser, extract words that contain at least 2 vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32dec09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "#ser.item\n",
    "ser[ser.str.count(pat=r'[AaEeIiOoUu]') >=2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44177063",
   "metadata": {},
   "source": [
    "25) Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e85fe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    rameses@egypt.com\n",
       "2            matt@t.co\n",
       "3    narendra@modi.com\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "#ser[ser.str.count(pat=r'[AaEeIiOoUu]') >=2]\n",
    "emails.str.match(pat=pattern)\n",
    "emails[emails.str.match(pat=pattern)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fadf17",
   "metadata": {},
   "source": [
    "26) Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75855cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['carrot', 'apple', 'banana', 'carrot', 'apple', 'apple', 'carrot', 'banana', 'banana', 'apple']\n",
      "apple     5.750000\n",
      "banana    6.666667\n",
      "carrot    4.000000\n",
      "dtype: float64\n",
      "               1\n",
      "apple   5.750000\n",
      "banana  6.666667\n",
      "carrot  4.000000\n",
      "        0     1\n",
      "0  carrot   1.0\n",
      "1   apple   2.0\n",
      "2  banana   3.0\n",
      "3  carrot   4.0\n",
      "4   apple   5.0\n",
      "5   apple   6.0\n",
      "6  carrot   7.0\n",
      "7  banana   8.0\n",
      "8  banana   9.0\n",
      "9   apple  10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Learner_XZHCG217\\AppData\\Local\\Temp\\ipykernel_14080\\2736184122.py:19: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  print(df.groupby(fruit).mean())\n"
     ]
    }
   ],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weights.tolist())\n",
    "print(fruit.tolist())\n",
    "#examples\n",
    "#> [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "#> ['banana', 'carrot', 'apple', 'carrot', 'carrot', 'apple', 'banana', 'carrot', 'apple', 'carrot']\n",
    "\n",
    "# in SQL we do group by fruit\n",
    "# this is series function\n",
    "\n",
    "print(weights.groupby(fruit).mean())\n",
    "\n",
    "#another way\n",
    "\n",
    "#df= fruit.to_frame # created dataframe\n",
    "df = pd.concat([fruit, weights], axis =1) # series has concat and we are assigning to dataframe\n",
    "df\n",
    "print(df.groupby(fruit).mean())\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8ebe7",
   "metadata": {},
   "source": [
    "27) Compute the euclidean distance between series (points) p and q, without using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c9cbfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "dist = np.sqrt(np.sum([(a-b)*(a-b) for a, b in zip(p,q)])) # step by step  (for loop is not needed as we are using series)\n",
    "print(dist)\n",
    "\n",
    "dist = np.sqrt(np.sum([(p-q)*(p-q)])) #(for loop is not needed as we are using series)\n",
    "\n",
    "\n",
    "sum((p - q)**2)**.5  #.5 is square root\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8326a3",
   "metadata": {},
   "source": [
    "28) Get the positions of peaks (values surrounded by smaller values on both sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ea30aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 -7  1  5  1 -8  5 -4]\n",
      "[ 1 -1  1  1  1 -1  1 -1]\n",
      "[-2  2  0  0 -2  2 -2]\n",
      "[1 5 7]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "''''dd = np.diff(np.sign(np.diff(ser)))   # sign means absolute value\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs '''\n",
    "\n",
    "print(np.diff(ser))    # printing the difference\n",
    "print(np.sign(np.diff(ser)))     # # change the numbers in 1 and -1 for the numbers\n",
    "dd= np.diff(np.sign(np.diff(ser)))  \n",
    "print(dd)                              \n",
    "peak_locs = np.where(dd == -2)[0] + 1  # where ever the index is -2... printing -2 index\n",
    "print(peak_locs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4299df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 5, 7], dtype='int64')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "ser.diff()\n",
    "ser.diff().where(ser.diff()<0)\n",
    "ser.diff().where(ser.diff()<0).dropna()\n",
    "ser.diff().where(ser.diff()<0).dropna().index\n",
    "ser.diff().where(ser.diff()<0).dropna().index-1  # we want peak number... one number minus other is -ve means the before number is high.\n",
    "                                                # so we take before index... index-1\n",
    "\n",
    "# this code working one way ..... not comparing both sides (works for the series in the given question... but not with other series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5675f",
   "metadata": {},
   "source": [
    "29) Replace the spaces in my_str with the least frequent character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d4aff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "char = pd.Series(list(my_str)).value_counts().index[-1]\n",
    "my_str = my_str.replace(' ', char)\n",
    "my_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b95f0",
   "metadata": {},
   "source": [
    "30) Create a timeseries starting at ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4cd8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    1\n",
       "2000-01-08    5\n",
       "2000-01-15    9\n",
       "2000-01-22    1\n",
       "2000-01-29    6\n",
       "2000-02-05    1\n",
       "2000-02-12    2\n",
       "2000-02-19    4\n",
       "2000-02-26    5\n",
       "2000-03-04    9\n",
       "2000-03-11    9\n",
       "2000-03-18    2\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.date_range('2001-01-01', periods=10, freq='W-SAT') # getting the date range\n",
    "ser\n",
    "pd.Series(np.random.randint(1,10,10), ser) # assigning the date range to 10 random numbers\n",
    "ser = pd.Series(np.random.randint(1,10,10), ser) # assign the random in to series again\n",
    "ser\n",
    "\n",
    "# ser = pd.date_range('2000-01-01', periods=12, freq='W-SAT') # we giving 12 periods and assigning to 10 random numbers\n",
    "# ser = pd.Series(np.random.randint(1,10,12), ser)\n",
    "# ser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a17176",
   "metadata": {},
   "source": [
    "31) Series ser has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8a10d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n",
      "DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',\n",
      "               '2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "# print(ser)\n",
    "# print(ser.index)\n",
    "# print(ser.index[0])\n",
    "# pd.date_range(ser.min(), ser.max())\n",
    "\n",
    "ser.resample('D').ffill()  # (frequncy)\n",
    "ser.resample('2D').ffill() # (2 days frequency)\n",
    "ser.resample('3D').ffill()\n",
    "ser.resample('D').first() # resample is to generate the frequency.... ffill is filling the values\n",
    "\n",
    "print(pd.date_range(start=ser.index[0], freq='D' , end=ser.index[-1]))  # taking the start and end from the given range\n",
    "\n",
    "\n",
    "#> 2000-01-01     1.0\n",
    "#> 2000-01-03    10.0\n",
    "#> 2000-01-06     3.0\n",
    "#> 2000-01-08     NaN\n",
    "#> dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ebefa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-03    10.0\n",
       "2000-01-05     3.0\n",
       "2000-01-07     NaN\n",
       "Freq: 2D, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "ser.resample('2D').first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b261ac",
   "metadata": {},
   "source": [
    "32) Compute autocorrelations for the first 10 lags of ser. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "052982b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.16949531  13.82954668  -2.17615027  11.31602571  -7.79600769\n",
      "  11.74391966   0.77998522   1.54227774  10.78357336 -18.81523682\n",
      "  18.3670861   15.0921715   -1.2029188   17.37842837   4.77557303\n",
      "  -8.50296061   6.22491455  -9.92165244  13.45552842   7.30378687]\n",
      "[1.0, -0.17980586326516895, 0.2116300648518919, 0.3291278009683496, -0.3355883355361565, 0.4478014447208408, 0.056123514753245035, -0.016172093010774515, 0.40184450664387683, -0.29156525017831264, 0.12449910425647895]\n",
      "0.4478014447208408\n"
     ]
    }
   ],
   "source": [
    "'''ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "# print(np.random.normal(1, 10, 20)) # generating numbers .  1. mean, 2. (10) (standard deviation) width... scale, 3.20 is the size\n",
    "# standard deviation  --- (formula)\n",
    "np.random.normal(1, 10, 20) # negative numbers are coming\n",
    "r = np.random.normal(1, 10, 20)\n",
    "print(r)\n",
    "ser = pd.Series(np.arange(20) + r)\n",
    "ser.autocorr(10) # auto corelation'''\n",
    "\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "r = np.random.normal(1, 10, 20)\n",
    "print(r)\n",
    "ser = pd.Series(np.arange(20) + r)\n",
    "ser2 = []\n",
    "for i in range(11):\n",
    "    ser2.append(ser.autocorr(i))\n",
    "\n",
    "print(ser2)\n",
    "print(max(ser2[1:])) # we are getting the max value.... but not the index of max value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1756a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.07, 0.28, 0.1, 0.31, 0.04, 0.01, 0.04, -0.1, 0.12]\n",
      "Lag having highest correlation:  5\n"
     ]
    }
   ],
   "source": [
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae48ebc",
   "metadata": {},
   "source": [
    "33) Import every 50th row of BostonHousing dataset as a dataframe.\n",
    "    https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09888bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
      "49   0.21977   0.0   6.91     0  0.448  5.602  62.0  6.0877    3  233   \n",
      "99   0.06860   0.0   2.89     0  0.445  7.416  62.5  3.4952    2  276   \n",
      "149  2.73397   0.0  19.58     0  0.871  5.597  94.9  1.5257    5  403   \n",
      "199  0.03150  95.0   1.47     0  0.403  6.975  15.3  7.6534    3  402   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "49      17.9  396.90  16.20  19.4  \n",
      "99      18.0  396.90   6.19  33.2  \n",
      "149     14.7  351.85  21.45  15.4  \n",
      "199     17.0  396.90   4.56  34.9  \n",
      "      crim  zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.21977   0   6.91     0  0.448  5.602  62.0  6.0877    3  233     17.9   \n",
      "1  0.06860   0   2.89     0  0.445  7.416  62.5  3.4952    2  276     18.0   \n",
      "2  2.73397   0  19.58     0  0.871  5.597  94.9  1.5257    5  403     14.7   \n",
      "3  0.03150  95   1.47     0  0.403  6.975  15.3  7.6534    3  402     17.0   \n",
      "4  0.19073  22   5.86     0  0.431  6.718  17.5  7.8265    7  330     19.1   \n",
      "5  0.05561  70   2.24     0  0.400  7.041  10.0  7.8278    5  358     14.8   \n",
      "6  0.02899  40   1.25     0  0.429  6.939  34.5  8.7921    1  335     19.7   \n",
      "7  9.91655   0  18.10     0  0.693  5.852  77.8  1.5004   24  666     20.2   \n",
      "8  7.52601   0  18.10     0  0.713  6.417  98.3  2.1850   24  666     20.2   \n",
      "9  0.17783   0   9.69     0  0.585  5.569  73.5  2.3999    6  391     19.2   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0  396.90  16.20  19.4  \n",
      "1  396.90   6.19  33.2  \n",
      "2  351.85  21.45  15.4  \n",
      "3  396.90   4.56  34.9  \n",
      "4  393.74   6.56  26.2  \n",
      "5  371.58   4.74  29.0  \n",
      "6  389.85   5.89  26.6  \n",
      "7  338.16  29.97   6.3  \n",
      "8  304.21  19.31  13.0  \n",
      "9  395.77  15.10  17.5  \n"
     ]
    }
   ],
   "source": [
    "path=\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "df= pd.read_csv(path)\n",
    "df1 = pd.read_csv(path, skiprows=lambda x : x%50 != 0)\n",
    "print(df.iloc[[49,99,149,199]])\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10cbec",
   "metadata": {},
   "source": [
    "34) Import the boston housing dataset, but while importing change the 'medv' (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c39256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "      <th>new_medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv new_medv  \n",
       "0  396.90   4.98  24.0      Low  \n",
       "1  396.90   9.14  21.6      Low  \n",
       "2  392.83   4.03  34.7     34.7  \n",
       "3  394.63   2.94  33.4     33.4  \n",
       "4  396.90   5.33  36.2     36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_medv\"] = df[\"medv\"].where((df[\"medv\"] > 0 and  df[\"medv\"] <= 25), \"Low\")\n",
    "# df[\"new_medv\"] = df[\"medv\"].where(df[\"medv\"] < 25, \"High\")\n",
    "df.head()\n",
    "#where will work only if condition is false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83078db",
   "metadata": {},
   "source": [
    "35) Create a dataframe with rows as strides from the series \"L\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9dfeba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "order must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m L \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\u001b[39mrange\u001b[39m(\u001b[39m15\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m array\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mreshape(L,\u001b[39m4\u001b[39;49m,\u001b[39m6\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mTypeError\u001b[0m: order must be str, not int"
     ]
    }
   ],
   "source": [
    "L = pd.Series(range(15))\n",
    "array=np.reshape(L,4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36f890",
   "metadata": {},
   "source": [
    "36) Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ecddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim  medv\n",
      "0    0.00632  24.0\n",
      "1    0.02731  21.6\n",
      "2    0.02729  34.7\n",
      "3    0.03237  33.4\n",
      "4    0.06905  36.2\n",
      "..       ...   ...\n",
      "501  0.06263  22.4\n",
      "502  0.04527  20.6\n",
      "503  0.06076  23.9\n",
      "504  0.10959  22.0\n",
      "505  0.04741  11.9\n",
      "\n",
      "[506 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2=df[['crim','medv']]\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830c591",
   "metadata": {},
   "source": [
    "37) Get the number of rows, columns, datatype and summary statistics of each column of the Cars93 dataset. Also get the numpy array and list equivalent of the dataframe.\n",
    "\n",
    "https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fe83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e458e997",
   "metadata": {},
   "source": [
    "38) Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70df19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Manufacturer        89 non-null     object \n",
      " 1   Model               92 non-null     object \n",
      " 2   Type                90 non-null     object \n",
      " 3   Min.Price           86 non-null     float64\n",
      " 4   Price               91 non-null     float64\n",
      " 5   Max.Price           88 non-null     float64\n",
      " 6   MPG.city            84 non-null     float64\n",
      " 7   MPG.highway         91 non-null     float64\n",
      " 8   AirBags             87 non-null     object \n",
      " 9   DriveTrain          86 non-null     object \n",
      " 10  Cylinders           88 non-null     object \n",
      " 11  EngineSize          91 non-null     float64\n",
      " 12  Horsepower          86 non-null     float64\n",
      " 13  RPM                 90 non-null     float64\n",
      " 14  Rev.per.mile        87 non-null     float64\n",
      " 15  Man.trans.avail     88 non-null     object \n",
      " 16  Fuel.tank.capacity  85 non-null     float64\n",
      " 17  Passengers          91 non-null     float64\n",
      " 18  Length              89 non-null     float64\n",
      " 19  Wheelbase           92 non-null     float64\n",
      " 20  Width               87 non-null     float64\n",
      " 21  Turn.circle         88 non-null     float64\n",
      " 22  Rear.seat.room      89 non-null     float64\n",
      " 23  Luggage.room        74 non-null     float64\n",
      " 24  Weight              86 non-null     float64\n",
      " 25  Origin              88 non-null     object \n",
      " 26  Make                90 non-null     object \n",
      "dtypes: float64(18), object(9)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "path='https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv'\n",
    "cars93=pd.read_csv(path)\n",
    "cars93.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e81856",
   "metadata": {},
   "source": [
    "39) Rename the column \"Type\" as \"CarType\" in the previous data and replace the ‘.’ in column names with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e517e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5989022c",
   "metadata": {},
   "source": [
    "40) Check if the data from #37 has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7e0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed881438",
   "metadata": {},
   "source": [
    "41) Count the number of missing values in each column of the previous data. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf14525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5abbc84",
   "metadata": {},
   "source": [
    "42) Replace missing values in Min.Price and Max.Price columns with their respective mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acfe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d26407",
   "metadata": {},
   "source": [
    "43) In the previous data, use apply method to replace the missing values in Min.Price with the column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6209b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c193bc",
   "metadata": {},
   "source": [
    "44) Get the first column (a) in the data as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2fbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83334c4f",
   "metadata": {},
   "source": [
    "45) Actually 3 questions.\n",
    "\n",
    "In the data, interchange columns 'a' and 'c'.\n",
    "\n",
    "Create a generic function to interchange two columns, without hardcoding column names.\n",
    "\n",
    "Sort the columns in reverse alphabetical order, that is colume 'e' first through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8706e8d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arrange'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(np\u001b[39m.\u001b[39;49marrange(\u001b[39m20\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m5\u001b[39m),columns\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mabcde\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[39m#arrange the data in rows and columns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#reshape(-1,5) .. is 5 columns and as many rows as we need\u001b[39;00m\n\u001b[0;32m      5\u001b[0m x \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\__init__.py:284\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrange'"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(np.arrange(20).reshape(-1,5),columns=('abcde'))\n",
    "#arrange the data in rows and columns\n",
    "#reshape(-1,5) .. is 5 columns and as many rows as we need\n",
    "\n",
    "x = df['a']\n",
    "y = df['c']\n",
    "\n",
    "df['a'] = y\n",
    "df['c']  = x\n",
    "\n",
    "df.rename(columns={'a':'c','c':'a'}, inplace=True)\n",
    "df\n",
    "#df.rename(columns={'a':'c','c':'a'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swapping the columns\n",
    "\n",
    "x = df['a']\n",
    "y = df['c']\n",
    "\n",
    "df['a'] = y\n",
    "df['c']  = x\n",
    "\n",
    "df.rename(columns={'a':'c','c':'a'}, inplace=True)\n",
    "#swapping the columns\n",
    "def swap(df, uno, dos):\n",
    "    x = df[uno]\n",
    "    y = df[dos]\n",
    "    df[uno] = y\n",
    "    df[dos] = x\n",
    "    df.rename(columns = {uno:dos, dos:uno}, inplace = True)\n",
    "    return df\n",
    "tres_df = swap(df, 'a', 'c')\n",
    "print(tres_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd957988",
   "metadata": {},
   "source": [
    "46) Change the pandas display settings on printing the dataframe so it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f69a323b",
   "metadata": {},
   "source": [
    "47) Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aa0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa22aec",
   "metadata": {},
   "source": [
    "48) Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d4f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    62.849261\n",
      "1    20.483078\n",
      "2    39.077493\n",
      "3    18.785611%\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "#df is  object and can work as string but string methods cant be used \n",
    "print(df['random'].mul(100).round(2).astype(str)+'%')\n",
    "\n",
    "#>      random\n",
    "#> 0    .689723\n",
    "#> 1    .957224\n",
    "#> 2    .159157\n",
    "#> 3    .21082"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829030ce",
   "metadata": {},
   "source": [
    "49) From the cars data, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b439593c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['manufacturer', 'model', 'type'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(path)\n\u001b[1;32m----> 3\u001b[0m df[[\u001b[39m'\u001b[39;49m\u001b[39mmanufacturer\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39miloc[::\u001b[39m20\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[39m#loc- location index label\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#iloc -- \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6173\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6171\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6172\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['manufacturer', 'model', 'type'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "path='https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv'\n",
    "df=pd.read_csv(path)\n",
    "df[['manufacturer','model','type']].iloc[::20]\n",
    "#loc- location index label\n",
    "#iloc -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38155b7",
   "metadata": {},
   "source": [
    "50) In the cars data, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf131e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01c9b73",
   "metadata": {},
   "source": [
    "51) Find the row position of the 5th largest value of column 'a' in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15321302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df76d19",
   "metadata": {},
   "source": [
    "52) In ser, find the position of the 2nd largest value greater than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61330d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.13333333333333\n",
      "0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "5      NaN\n",
      "6      NaN\n",
      "7      NaN\n",
      "8      NaN\n",
      "9     24.0\n",
      "10    44.0\n",
      "11    25.0\n",
      "12    27.0\n",
      "13    65.0\n",
      "14    82.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15)).astype(\"float\")\n",
    "m=ser.astype(\"float\").mean().round()\n",
    "print(m)\n",
    "\n",
    "s = pd.Series(sorted(ser.astype(\"float\")))\n",
    "# print(s)\n",
    "\n",
    "val_grt_mean = pd.Series(s.where(s > m).dropna()).astype(\"float\")\n",
    "v = val_grt_mean.iloc[1]\n",
    "print(v)\n",
    "\n",
    "print(ser[ser.values==v].index)\n",
    "print(ser[ser==v].index)\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaae1b8",
   "metadata": {},
   "source": [
    "53) Get the last two rows of df whose row sum is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab30612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4dac7e",
   "metadata": {},
   "source": [
    "54) Replace all values of ser in the lower 5%ile and greater than 95%ile with respective 5th and 95th %ile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407723d9",
   "metadata": {},
   "source": [
    "55) Reshape df to the largest possible square with negative values removed. Drop the smallest values if need be. The order of the positive numbers in the result should remain the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa891f3",
   "metadata": {},
   "source": [
    "56) Swap rows 1 and 2 in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca60052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97144928",
   "metadata": {},
   "source": [
    "57) Reverse all the rows of dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09f84f",
   "metadata": {},
   "source": [
    "58) Get one-hot encodings for column 'a' in the dataframe df and append it as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "    a   b   c   d   e\n",
    "0   0   1   2   3   4\n",
    "1   5   6   7   8   9\n",
    "2  10  11  12  13  14\n",
    "3  15  16  17  18  19\n",
    "4  20  21  22  23  24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5295b8b",
   "metadata": {},
   "source": [
    "59) Obtain the column name with the highest number of row-wise maximum’s in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcf24b",
   "metadata": {},
   "source": [
    "60) Create a new column such that, each row contains the row number of nearest row-record by euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "df\n",
    "#     p   q   r   s\n",
    "# a  57  77  13  62\n",
    "# b  68   5  92  24\n",
    "# c  74  40  18  37\n",
    "# d  80  17  39  60\n",
    "# e  93  48  85  33\n",
    "# f  69  55   8  11\n",
    "# g  39  23  88  53\n",
    "# h  63  28  25  61\n",
    "# i  18   4  73   7\n",
    "# j  79  12  45  34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1791",
   "metadata": {},
   "source": [
    "61) Compute maximum possible absolute correlation value of each column against other columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef471",
   "metadata": {},
   "source": [
    "62) Compute the minimum-by-maximum for every row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7368340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d2276",
   "metadata": {},
   "source": [
    "63) Create a new column 'penultimate' which has the second largest value of each row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c1042",
   "metadata": {},
   "source": [
    "64) Normalize all columns of df by subtracting the column mean and divide by standard deviation.\n",
    "Range all columns of df such that the minimum value in each column is 0 and max is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da28502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26e808",
   "metadata": {},
   "source": [
    "65) Compute the correlation of each row of df with its succeeding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fca730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57341a09",
   "metadata": {},
   "source": [
    "66) Replace both values in both diagonals of df with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721432ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "df\n",
    "#     0   1   2   3   4   5   6   7   8   9\n",
    "# 0  11  46  26  44  11  62  18  70  68  26\n",
    "# 1  87  71  52  50  81  43  83  39   3  59\n",
    "# 2  47  76  93  77  73   2   2  16  14  26\n",
    "# 3  64  18  74  22  16  37  60   8  66  39\n",
    "# 4  10  18  39  98  25   8  32   6   3  29\n",
    "# 5  29  91  27  86  23  84  28  31  97  10\n",
    "# 6  37  71  70  65   4  72  82  89  12  97\n",
    "# 7  65  22  97  75  17  10  43  78  12  77\n",
    "# 8  47  57  96  55  17  83  61  85  26  86\n",
    "# 9  76  80  28  45  77  12  67  80   7  63\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c483b",
   "metadata": {},
   "source": [
    "67) Using a key in a grouped data frame. From df_grouped, get the group belonging to 'apple' as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8028ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb901",
   "metadata": {},
   "source": [
    "68) In df, find the second largest value of 'taste' for 'banana'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde89cb",
   "metadata": {},
   "source": [
    "69) In df, Compute the mean price of every fruit, while keeping the fruit as another column instead of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaa372",
   "metadata": {},
   "source": [
    "70) Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a250adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb8fe",
   "metadata": {},
   "source": [
    "71) Get the positions where the value of two columns match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da5c86",
   "metadata": {},
   "source": [
    "72) Create two new columns in df, one of which is a lag1 (shift column a down by 1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "    a   b   c   d\n",
    "0  66  34  76  47\n",
    "1  20  86  10  81\n",
    "2  75  73  51  28\n",
    "3   1   1   9  83\n",
    "4  30  47  67   4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a01f7",
   "metadata": {},
   "source": [
    "73) Get the frequency of unique values in the entire dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d182d",
   "metadata": {},
   "source": [
    "74) Split the string column in df to form a dataframe with 3 columns as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
